<?xml version="1.0" ?>

<!-- # Introduction

In this tutorial, we will build an audio classifier. It takes sound from a microphone or a file and uses a neural network to detect if a user is speaking. If this is the case, the pipeline will predict the gender of the speaker and if he or she is laughing. For more information, visit [VadNnet](https://github.com/hcmlab/vadnet) project page. Before you start, make sure to install [Tensorflow](https://www.tensorflow.org/) by running the `install_tensorflow.cmd` from the root folder.

--><!---->

<pipeline ssi-v="1">
	
	<register>
		<load name="graphic"/>
		<load name="audio" depend="ssidialog.dll"/>
		<load name="ioput"/>		
		<load name="signal"/>		
		<load name="python"/>
		<load name="control"/>
	</register>

	<!-- # Live input

	We use a `gate` to switch between live and file input. The option is set in a configuration file:
	
	\input{path=01_input.pipeline-config}
	
	In live input is selected (i.e. `audio:live=true`), the user can further select if the input comes from a microphone (`audio:live:mic=true`) or the output of the soundcard is captured (`audio:live:mic=false`). In the later case make sure to set the output format of your soundcard to `16 bit` and `48000 Hz`.
	
	![](https://raw.githubusercontent.com/hcmlab/vadnet/master/pics/loopback.png)	
	
	-->
	<gate open="$(audio:live)">	
		<gate open="$(audio:live:mic)">	
			<sensor create="Audio" option="options\microphone" sr="48000" scale="true" blockInSamples="512">
				<output channel="audio" pin="audio"/>
			</sensor>
		</gate>
		<gate close="$(audio:live:mic)">	
			<sensor create="AudioLoopBack" option="options\loopback" scale="true">
				<output channel="audio" pin="audio">			
					<transformer create="Selector" indices="0"/>
				</output>
			</sensor>
		</gate>
	</gate>
	<!---->
	
	<!-- # File input
	
	If file input is selected (i.e. `audio:live=false`), two files are used for input: one containing speech and another one containing noise. If you use your own files, makes sure they are `mono` and sampled at `48000 Hz`.
	
	-->
	<gate close="$(audio:live)">
		<sensor create="WavReader:reader" path="data\speech.wav" loop="true">			
			<output channel="audio" pin="speech_raw" size="2.0s"/>
		</sensor>		
		<sensor create="WavReader:reader" path="data\noise.wav" loop="true">			
			<output channel="audio" pin="noise_raw" size="2.0s"/>
		</sensor>		
	</gate>			
	<!---->		

	<!-- # Mixer
	
	In case of file input, we need to mix the two sources first. Before we do this, we multiply them with weights that can be adjusted at run-time with a slider. This way, the user can continuously control the amount of speech and noise in the audio signal. Then we add a mixer that combines the two signals.
	
	-->
	<gate close="$(audio:live)">
		<transformer create="Multiply:speech" factor="0.0">
			<input pin="speech_raw" frame="4800"/>
			<output pin="speech"/>
		</transformer>	
		<transformer create="Multiply:noise" factor="0.0">
			<input pin="noise_raw" frame="4800"/>
			<output pin="noise"/>
		</transformer>	
		<runnable create="ControlSlider:slider" title="SPEECH" id="speech" name="factor" defval="0.0" minval="0.0" maxval="1.0"/>
		<runnable create="ControlSlider:slider" title="NOISE" id="noise" name="factor" defval="0.0" minval="0.0" maxval="0.25"/>		
		<transformer create="STKAudioMixer:mixer">
			<input pin="speech;noise" frame="4800"/>
			<output pin="audio"/>
		</transformer>				
	</gate>
	<!---->					
	
	<!-- # Playback and Visualization
	
	Finally, we play back the audio signal (in case of file input only) and visualize it.	
	
	-->
	<gate close="$(audio:live)">		
		<consumer create="AudioPlayer" option="options\aplayer">
			<input pin="audio" frame="0.1s"/>
		</consumer>	
	</gate>
	<consumer create="SignalPainter:plot" title="AUDIO" size="10" type="2">
		<input pin="audio" frame="0.2s" delta="0"/>
	</consumer>			
	<!---->				
		
	<object create="Decorator" icon="true" title="Pipeline">
		<area pos="0,0,400,600">console</area>
		<area pos="400,0,400,600">plot*</area>		
		<area pos="800,0,400,200" nh="1">slider*</area>	
		<area pos="800,300,400,300">monitor</area>	
	</object>		

</pipeline>
